# URL-based Q&A System 

This project implements a semantic search engine using OpenAI's GPT models and Pinecone. It allows users to upload URLs to extract content, update the database with semantic embeddings, and ask questions. The responses are generated by querying Pinecone and leveraging OpenAI's powerful language models to provide context-based answers.

## Table of Contents
- [Features](#features)
- [Technologies Used](#technologies-used)
- [Architecture](#architecture)
- [Installation](#installation)
- [Environment Variables](#environment-variables)
- [Running the Project Locally](#running-the-project-locally)
- [How to Use](#how-to-use)
- [Contributing](#contributing)
- [License](#license)

## Features

- **Semantic Search Engine**: Queries are matched against embedded text chunks using Pinecone's vector database.
- **Question Answering**: Uses OpenAI GPT models to answer user queries in natural language based on the retrieved text.
- **Real-time Database Updates**: Extracts text from URLs and updates the Pinecone index.
- **Streamlit Interface**: User-friendly UI for updating the database and asking questions.

## Technologies Used

- **Streamlit**: Web framework for the interface.
- **OpenAI GPT-4**: Language models for Q&A generation.
- **Pinecone**: Vector database for semantic search.
- **BeautifulSoup**: Web scraping utility for extracting plain text from URLs.
- **Sentence Transformers**: Pre-trained models for generating text embeddings.

## Architecture

1. User Input: Users can either ask a question or update the database by providing a URL.
2. Web Scraping: Extracts and splits content from the provided URL.
3. Text Embedding: Converts scraped text into semantic embeddings using SentenceTransformer.
4. Pinecone Indexing: Embeddings are stored in Pinecone for fast and efficient search.
5. Question Query: User questions are embedded and matched with the stored text.
6. Answer Generation: Matched text is used as context for generating answers using OpenAI GPT models.

## Installation

### Clone the Repository

```bash
git clone https://github.com/kumarshivesh/qa-from-given-url.git
```

### Create and Activate a Virtual Environment

```
python -m venv .venv
source .venv/bin/activate   # On Windows use `.venv\Scripts\activate`
```

### Install Dependencies

```
pip install -r requirements.txt
```

## Environment Variables

Create a .env file in the root directory of the project and add the following variable(s):

```
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
```

## Running the Project Locally

```
streamlit run main.py
```

## How to Use

### 1. Update the Database: 

1. Choose "Update the Database".
2. Enter the URL of the document you want to extract content from.
3. Click Submit.
4. The extracted content is embedded and added to the Pinecone index.


### 2. Ask a Question:

1. Choose "Ask a question".
2. Enter your query in the text input field.
3. Click Submit.
4. The matched content is retrieved from the Pinecone index, and the GPT model generates an answer.

## Contributing

Contributions are welcome! To contribute:

1. Fork the project
2. Create a feature branch (git checkout -b feature/my-feature)
3. Commit your changes (git commit -m 'Add new feature')
4. Push to the branch (git push origin feature/my-feature)
5. Create a new Pull Request

## License

This project is licensed under the MIT License. 



